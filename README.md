# programmercarl_learn
一个学习 代码随想录 的笔记  

# 算法性能分析  

## 时间复杂度  

### 什么是时间复杂度  

**时间复杂度是一个函数，它定性描述该算法的运行时间。**  
假设算法的问题规模为n，那么操作单元数量便用函数f(n)来表示，随着数据规模n的增大，算法执行时间的增长率和f(n)的增长率相同，  
这称作为算法的渐近时间复杂度，简称时间复杂度，记为 O(f(n))。

### 什么是大O  
《算法导论》给出的解释：**大O用来表示上界**，当用它作为算法的最坏情况运行时间的上界，就是对任意数据输入的运行时间的上界。  

同样算法导论给出了例子：拿插入排序来说，插入排序的时间复杂度我们都说是O(n^2) 。  

输入数据的形式对程序运算时间是有很大影响的，在数据本来有序的情况下时间复杂度是O(n)，但如果数据是逆序的话，插入排序的时间复杂度就是O(n^2)，也就对于所有输入情况来说，最坏是O(n^2) 的时间复杂度，所以称插入排序的时间复杂度为O(n^2)。  

同样的同理再看一下快速排序，都知道快速排序是O(nlogn)，但是当数据已经有序情况下，快速排序的时间复杂度是O(n^2) 的，**所以严格从大O的定义来讲，快速排序的时间复杂度应该是O(n^2)**。  

但是**我们依然说快速排序是O(nlogn)的时间复杂度，这个就是业内的一个默认规定**，这里说的**O代表的就是一般情况，而不是严格的上界**。  如图所示：
![插入排序算法复杂度比较](https://code-thinking-1253855093.file.myqcloud.com/pics/20200728185745611-20230310123844306.png)  
**面试中说道算法的时间复杂度是多少指的都是一般情况。**  

### 不同数据规模的差异
![不同数据规模下，不同的算法之间复杂度的比较](https://code-thinking-1253855093.file.myqcloud.com/pics/20200728191447384-20230310124015324.png)  
在决定使用哪些算法的时候，不是时间复杂越低的越好（因为简化后的时间复杂度忽略了常数项等等），要考虑数据规模，如果数据规模很小甚至可以用O(n^2)的算法比O(n)的更合适（在有常数项的时候）。  

就像上图中 O(5n^2) 和 O(100n) 在n为20之前 很明显 O(5n^2)是更优的，所花费的时间也是最少的。  

那为什么在计算时间复杂度的时候要忽略常数项系数呢，也就说O(100n) 就是O(n)的时间复杂度，O(5n^2) 就是O(n^2)的时间复杂度，而且要默认O(n) 优于O(n^2) 呢 ？  

这里就又涉及到大O的定义，**因为大O就是数据量级突破一个点且数据量级非常大的情况下所表现出的时间复杂度，这个数据量也就是常数项系数已经不起决定性作用的数据量**。  

例如上图中20就是那个点，n只要大于20 常数项系数已经不起决定性作用了。  

**所以我们说的时间复杂度都是省略常数项系数的，是因为一般情况下都是默认数据规模足够的大，基于这样的事实，给出的算法时间复杂的的一个排行如下所示：**  

O(1)常数阶 < O(logn)对数阶 < O(n)线性阶 < O(nlogn)线性对数阶 < O(n^2)平方阶 < O(n^3)立方阶 < O(2^n)指数阶  

但是也要注意大常数，如果这个常数非常大，例如10^7 ，10^9 ，那么常数就是不得不考虑的因素了。  

### 复杂表达式的化简  
有时候我们去计算时间复杂度的时候发现不是一个简单的O(n) 或者O(n^2)， 而是一个复杂的表达式，例如：
```
O(2*n^2 + 10*n + 1000)
```  
最后可以直接化简为：  
```
O(n^2)
```  
### O(logn)中的log是以什么为底？  
平时说这个算法的时间复杂度是logn的，那么一定是log 以2为底n的对数么？  

其实不然，也可以是以10为底n的对数，也可以是以20为底n的对数，但我们统一说 logn，也就是忽略底数的描述。  

为什么可以这么做呢？如下图所示：  


高中的换底公式，换了底，前面就是乘以一个常数，常数可以忽略，所以大O以什么为底的对数，这个底数是可以忽略的  
![log函数换底](https://code-thinking-1253855093.file.myqcloud.com/pics/20200728191447349-20230310124032001.png)  



# 数组  
## 数组理论基础  
数组是非常基础的数据结构，在面试中，考察数组的题目一般在思维上都不难，主要是考察对代码的掌控能力  

**数组是存放在连续内存空间上的相同类型数据的集合。**  
数组可以方便的通过下标索引的方式获取到下标下对应的数据。如图所示：  
![数据结构 - 数组](https://code-thinking.cdn.bcebos.com/pics/%E7%AE%97%E6%B3%95%E9%80%9A%E5%85%B3%E6%95%B0%E7%BB%84.png)  
* 数组下标都是从0开始的。  
* 数组内存空间的地址(物理地址)是连续的  
正是**因为数组的在内存空间的地址是连续的，所以我们在删除或者增添元素的时候，就难免要移动其他元素的地址。**  


**数组的元素是不能删的，只能覆盖。**  

二维数组表示如图：
![二维数组](https://code-thinking.cdn.bcebos.com/pics/%E7%AE%97%E6%B3%95%E9%80%9A%E5%85%B3%E6%95%B0%E7%BB%842.png)  

那么二维数组在内存的空间地址是连续的么？  

不同编程语言的内存管理是不一样的，以C++为例，在C++中二维数组是连续分布的。而java没有指针，二维数组的每一行头结点的地址是没有规则的，更谈不上连续。  

## 二分查找  
二分法的适用首先是有序的序列；其次还需要该序列没有重复元素，因为一旦有重复元素，使用二分查找法返回的元素下标可能不是唯一的  